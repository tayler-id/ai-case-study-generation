# Epic 2: Case Study Generation & V1 Canvas

**Epic Goal:** To deliver the core value of the application by implementing the agent's primary synthesis capability and the innovative real-time canvas UI. By the end of this epic, a user will be able to submit a scoped project and watch as the agent constructs a meaningful, narrative-driven case study from their data.

---

**Story 2.1: Basic Agent Synthesis Logic**
*As the system, I want to retrieve indexed data for a project and use an LLM to identify and write a simple chronological narrative, so that a foundational case study can be generated.*
* **Acceptance Criteria:**
    1. The agent can retrieve all text snippets for a given project scope from the vector database.
    2. The agent can construct a single, coherent prompt for a Large Language Model (LLM), instructing it to write a chronological summary.
    3. The agent successfully receives a complete markdown document from the LLM in response.
    4. The generated markdown is temporarily stored and associated with the user's request.

**Story 2.2: Implement Split-Screen Canvas UI**
*As a user, I want to see a split-screen layout with a chat interface on the left and a content canvas on the right, so that I have the primary workspace for interacting with the agent.*
* **Acceptance Criteria:**
    1. The main application view is structured as two primary, vertically divided panels.
    2. The left panel contains the chat history and a text input field.
    3. The right panel is a blank content area, ready to display the case study.
    4. The user can resize the panels by dragging the divider.

**Story 2.3: Real-Time Markdown Streaming**
*As a user, I want to see the markdown document being generated by the agent stream into the canvas in real-time, so that I get transparent feedback on the agent's progress.*
* **Acceptance Criteria:**
    1. When the case study generation is initiated, the right-hand canvas displays a "Writing..." status animation.
    2. As the LLM generates the markdown, the text is streamed token-by-token into the canvas.
    3. The streamed text is correctly rendered as formatted GitHub Flavored Markdown (e.g., headings, lists, bold text).
    4. The streaming process concludes when the agent finishes generating the document.

**Story 2.4: Agent Status Animations**
*As a user, I want to see distinct animations that communicate the agent's current status, so that I understand what is happening during the generation process.*
* **Acceptance Criteria:**
    1. A unique animation is displayed to signify the "Analyzing Data" phase (between user request and writing).
    2. A unique animation is displayed for the "Writing..." phase (during the markdown streaming).
    3. These animations are displayed in a non-intrusive way within the UI.
    4. The UI returns to a neutral state once the generation is complete.